{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PositiveNegativeTweets.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMqgC0w4y+GQaZtpUL0a2Xw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/susmitag/SentimentAnalysisTweet/blob/main/PositiveNegativeTweets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFlJt1rYYczM",
        "outputId": "fdde6b6a-a683-4649-af76-96ac4c8b3e8d"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "import random\n",
        "\n",
        "examples = []\n",
        "labels = []\n",
        "with open(\"./tweets_positive.txt\") as f:\n",
        "    for tweet in f: \n",
        "        examples.append(tweet) \n",
        "        labels.append('positive')\n",
        "\n",
        "with open(\"./tweets_negative.txt\") as f:\n",
        "    for tweet in f: \n",
        "        examples.append(tweet)\n",
        "        labels.append('negative')\n",
        "cv = CountVectorizer(\n",
        "    analyzer = 'word',\n",
        "    lowercase = False,\n",
        ")\n",
        "feat = cv.fit_transform(\n",
        "    examples\n",
        ")\n",
        "nd_feat = feat.toarray() # for easy usage\n",
        "\n",
        "train_x, test_x, train_y, test_y  = train_test_split(\n",
        "        nd_feat, \n",
        "        labels,\n",
        "        train_size=0.80, \n",
        "        random_state=1234)\n",
        "\n",
        "lreg = LogisticRegression()\n",
        "lreg = lreg.fit(X=train_x, y=train_y)\n",
        "pred_y = lreg.predict(test_x)\n",
        "\n",
        "gen = random.randint(0,len(test_x)-7)\n",
        "for idx in range(gen,gen+7):\n",
        "    print(pred_y[0])\n",
        "    index = nd_feat.tolist().index(test_x[idx].tolist())\n",
        "    #print(index)\n",
        "    #print(len(examples))\n",
        "    print(examples[index].strip())\n",
        "\n",
        "print(accuracy_score(test_y, pred_y))   \n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "negative\n",
            "\"@tommcfly back to England? South America will miss you  please come back soon\"\n",
            "negative\n",
            "\"Damn Lebron Kobe SHowin Who Should Of Been MVP This Year 2 Damn i'm lookin stupied hoping u guys can pull a comeback from 3-1 \"\n",
            "negative\n",
            "\"@tommcfly Tooom, come back to Brazil \"\n",
            "negative\n",
            "\"you know twitter is going places when oprah starts tweeting. oh and larry king! \"\n",
            "negative\n",
            "\"Wishes his xbox gets error 74 nd then he can send his xbox to germany to get it fixed for free rather than 2 red lighting all the time \"\n",
            "negative\n",
            "\"@MissSydneyJ Im good, lol... I feel awake \"\n",
            "negative\n",
            "\"Thanks to my new followers! \"\n",
            "0.800498753117207\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}